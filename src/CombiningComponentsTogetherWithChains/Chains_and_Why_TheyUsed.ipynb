{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ActiveLoop-Course/env/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.25) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "prompt_template = \"What is a word to replace the following: {word}?\"\n",
    "\n",
    "# Set the \"OPENAI_API_KEY\" environment variable before running following line.\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(prompt_template)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'artificial', 'text': '\\n\\nSynthetic'}\n",
      "Tokens Used: 14\n",
      "\tPrompt Tokens: 11\n",
      "\tCompletion Tokens: 3\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    print(llm_chain(\"artificial\"))\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\\n\\nSynthetic'},\n",
       " {'text': '\\n\\nCleverness'},\n",
       " {'text': '\\n\\nandroid'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [\n",
    "    {\"word\": \"artificial\"},\n",
    "    {\"word\": \"intelligence\"},\n",
    "    {\"word\": \"robot\"}\n",
    "]\n",
    "\n",
    "llm_chain.apply(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\nSynthetic', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nCleverness', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nandroid', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'prompt_tokens': 33, 'total_tokens': 42, 'completion_tokens': 9}, 'model_name': 'gpt-3.5-turbo-instruct'}, run=RunInfo(run_id=UUID('7bd3de61-de4f-438b-8519-5a1b79208f10')))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.generate(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSupporter'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"Looking at the context of '{context}'. What is an appropriate word to replace the following: {word}?\"\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate(template=prompt_template, input_variables=[\"word\", \"context\"]))\n",
    "\n",
    "llm_chain.predict(word=\"fan\", context=\"object\")\n",
    "# or llm_chain.run(word=\"fan\", context=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSupporter'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(word=\"fan\", context=\"humans\")\n",
    "# or llm_chain.run(word=\"fan\", context=\"humans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all possible words as substitute for 'artificial' as comma separated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['synthetic',\n",
       " 'man-made',\n",
       " 'fake',\n",
       " 'imitation',\n",
       " 'simulated',\n",
       " 'faux',\n",
       " 'fabricated',\n",
       " 'counterfeit',\n",
       " 'ersatz',\n",
       " 'false',\n",
       " 'pretend',\n",
       " 'mock',\n",
       " 'spurious',\n",
       " 'bogus',\n",
       " 'phony',\n",
       " 'contrived',\n",
       " 'manufactured',\n",
       " 'unnatural',\n",
       " 'inauthentic']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "words = \"words\"\n",
    "template = f\"\"\"List all possible {words} as substitute for 'artificial' as comma separated.\"\"\"\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate(template=template, output_parser=output_parser, input_variables=[]),\n",
    "    output_parser=output_parser)\n",
    "\n",
    "llm_chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Synthetic, simulated, man-made, fake, imitation, fabricated, manufactured, engineered, virtual, computer-generated, digital, non-natural, inauthentic, contrived, ersatz, pseudo, phony, false, unreal, pretend, counterfeit, spurious, bogus, sham, feigned, deceptive, fraudulent, specious, fallacious, misleading, delusive, illusory, fictitious, make-believe, imaginary, unreal, fictive, fanciful, fantastic, mythical, legendary, mythological, fabricated, created, contrived, invented, made-up, unreal, imaginary, fictional, mythical, legendary, mythological, fanciful, fantastic, make-believe, pretend, simulated, virtual, computer-generated, digital, non-natural, inauthentic, ersatz, pseudo, phony, false, counterfeit, spurious, bogus, sham, feigned, deceptive, fraudulent, specious, fallacious, misleading, delusive, illusory, fictitious, make-believe, imaginary, unreal, fictive, fanciful, fantastic, mythical, legendary, mythological, fabricated, created, contrived, invented, made-up, unreal, imaginary, fictional, mythical, legendary, mythological, fanciful, fantastic,'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"List all possible words as substitute for 'artificial' as comma separated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Imagined, conceptual, conceptualized, theoretical.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"And the next 4?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poet\n",
    "poet_template: str = \"\"\"You are an American poet, your job is to come up with\\\n",
    "poems based on a given theme.\n",
    "\n",
    "Here is the theme you have been asked to generate a poem on:\n",
    "{input}\\\n",
    "\"\"\"\n",
    "\n",
    "poet_prompt_template: PromptTemplate = PromptTemplate(\n",
    "    input_variables=[\"input\"], template=poet_template)\n",
    "\n",
    "# creating the poet chain\n",
    "poet_chain: LLMChain = LLMChain(\n",
    "    llm=llm, output_key=\"poem\", prompt=poet_prompt_template)\n",
    "\n",
    "# critic\n",
    "critic_template: str = \"\"\"You are a critic of poems, you are tasked\\\n",
    "to inspect the themes of poems. Identify whether the poem includes romantic expressions or descriptions of nature.\n",
    "\n",
    "Your response should be in the following format, as a Python Dictionary.\n",
    "poem: this should be the poem you received \n",
    "Romantic_expressions: True or False\n",
    "Nature_descriptions: True or False\n",
    "\n",
    "Here is the poem submitted to you:\n",
    "{poem}\\\n",
    "\"\"\"\n",
    "\n",
    "critic_prompt_template: PromptTemplate = PromptTemplate(\n",
    "    input_variables=[\"poem\"], template=critic_template)\n",
    "\n",
    "# creating the critic chain\n",
    "critic_chain: LLMChain = LLMChain(\n",
    "    llm=llm, output_key=\"critic_verified\", prompt=critic_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[poet_chain, critic_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "poem: Nature's Beauty\n",
      "Romantic_expressions: False\n",
      "Nature_descriptions: True\n"
     ]
    }
   ],
   "source": [
    "# Run the poet and critic chain with a specific theme\n",
    "theme: str = \"the beauty of nature\"\n",
    "review = overall_chain.run(theme)\n",
    "\n",
    "# Print the review to see the critic's evaluation\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mList all possible words as substitute for 'artificial' as comma separated.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n1. Synthetic\\n2. Man-made\\n3. Faux\\n4. Imitation\\n5. Simulated\\n6. Fake\\n7. Replicated\\n8. Manufactured\\n9. Counterfeit\\n10. Mock\\n11. Pretend\\n12. False\\n13. Inauthentic\\n14. Unnatural\\n15. Fabricated'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"List all possible words as substitute for 'artificial' as comma separated.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "\n",
    "{input}\"\"\"\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate(template=template, input_variables=[\"history\", \"input\"], output_parser=output_parser),\n",
    "    memory=ConversationBufferMemory(),\n",
    "    verbose=True)\n",
    "\n",
    "conversation.predict(input=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.base import Chain\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "class ConcatenateChain(Chain):\n",
    "    chain_1: LLMChain\n",
    "    chain_2: LLMChain\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        # Union of the input keys of the two chains.\n",
    "        all_input_vars = set(self.chain_1.input_keys).union(set(self.chain_2.input_keys))\n",
    "        return list(all_input_vars)\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return ['concat_output']\n",
    "\n",
    "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
    "        output_1 = self.chain_1.run(inputs)\n",
    "        output_2 = self.chain_2.run(inputs)\n",
    "        return {'concat_output': output_1 + output_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated output:\n",
      "\n",
      "\n",
      "Artificial means something that is made or produced by humans, rather than occurring naturally. It can also refer to something that is not genuine or authentic, but rather created or imitated to appear real.\n",
      "\n",
      "Synthetic\n"
     ]
    }
   ],
   "source": [
    "prompt_1 = PromptTemplate(\n",
    "    input_variables=[\"word\"],\n",
    "    template=\"What is the meaning of the following word '{word}'?\",\n",
    ")\n",
    "chain_1 = LLMChain(llm=llm, prompt=prompt_1)\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    input_variables=[\"word\"],\n",
    "    template=\"What is a word to replace the following: {word}?\",\n",
    ")\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
    "\n",
    "concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2)\n",
    "concat_output = concat_chain.run(\"artificial\")\n",
    "print(f\"Concatenated output:\\n{concat_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
