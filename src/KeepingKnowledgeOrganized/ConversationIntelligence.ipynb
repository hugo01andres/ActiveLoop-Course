{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Objection: \"There's no money.\"\n",
    "It could be that your prospect's business simply isn't big enough or generating enough cash right now to afford a product like yours. Track their growth and see how you can help your prospect get to a place where your offering would fit into their business.\n",
    "\n",
    "Objection: \"We don't have any budget left this year.\"\n",
    "A variation of the \"no money\" objection, what your prospect's telling you here is that they're having cash flow issues. But if there's a pressing problem, it needs to get solved eventually. Either help your prospect secure a budget from executives to buy now or arrange a follow-up call for when they expect funding to return.\n",
    "\n",
    "Objection: \"We need to use that budget somewhere else.\"\n",
    "Prospects sometimes try to earmark resources for other uses. It's your job to make your product/service a priority that deserves budget allocation now. Share case studies of similar companies that have saved money, increased efficiency, or had a massive ROI with you.\n",
    "\"\"\"\n",
    "\n",
    "# Split the text into a list using the keyword \"Objection: \"\n",
    "objections_list = text.split(\"Objection: \")[1:]  # We ignore the first split as it is empty\n",
    "\n",
    "# Now, prepend \"Objection: \" to each item as splitting removed it\n",
    "objections_list = [\"Objection: \" + objection for objection in objections_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ActiveLoop-Course/env/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.24) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import SeleniumURLLoader\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLakeLoader:\n",
    "    def __init__(self, source_data_path):\n",
    "        self.source_data_path = source_data_path\n",
    "        self.file_name = os.path.basename(source_data_path) # What we'll name our database \n",
    "        self.data = self.split_data()\n",
    "        if self.check_if_db_exists():\n",
    "            self.db = self.load_db()\n",
    "        else:\n",
    "            self.db = self.create_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(self):  \n",
    "    \"\"\"  \n",
    "    Preprocess the data by splitting it into passages.  \n",
    "\n",
    "    If using a different data source, this function will need to be modified.  \n",
    "\n",
    "    Returns:  \n",
    "        split_data (list): List of passages.  \n",
    "    \"\"\"  \n",
    "    with open(self.source_data_path, 'r') as f:  \n",
    "        content = f.read()  \n",
    "    split_data = re.split(r'(?=\\d+\\. )', content)\n",
    "    if split_data[0] == '':  \n",
    "        split_data.pop(0)  \n",
    "    split_data = [entry for entry in split_data if len(entry) >= 30]  \n",
    "    return split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(self):  \n",
    "    \"\"\"  \n",
    "    Load the database if it already exists.  \n",
    "\n",
    "    Returns:  \n",
    "        DeepLake: DeepLake object.  \n",
    "    \"\"\"  \n",
    "    return DeepLake(dataset_path=f'deeplake/{self.file_name}', embedding_function=OpenAIEmbeddings(), read_only=True)  \n",
    "\n",
    "def create_db(self):  \n",
    "    \"\"\"  \n",
    "    Create the database if it does not already exist.  \n",
    "\n",
    "    Databases are stored in the deeplake directory.  \n",
    "\n",
    "    Returns:  \n",
    "        DeepLake: DeepLake object.  \n",
    "    \"\"\"  \n",
    "    return DeepLake.from_texts(self.data, OpenAIEmbeddings(), dataset_path=f'deeplake/{self.file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(self, query):  \n",
    "    \"\"\"  \n",
    "    Query the database for passages that are similar to the query.  \n",
    "\n",
    "    Args:  \n",
    "        query (str): Query string.  \n",
    "\n",
    "    Returns:  \n",
    "        content (list): List of passages that are similar to the query.  \n",
    "    \"\"\"  \n",
    "    results = self.db.similarity_search(query, k=3)  \n",
    "    content = []  \n",
    "    for result in results:  \n",
    "        content.append(result.page_content)  \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DeepLakeLoader' object has no attribute 'split_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mDeepLakeLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/salestesting.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m, in \u001b[0;36mDeepLakeLoader.__init__\u001b[0;34m(self, source_data_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_data_path \u001b[38;5;241m=\u001b[39m source_data_path\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(source_data_path) \u001b[38;5;66;03m# What we'll name our database \u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_data\u001b[49m()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_if_db_exists():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_db()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DeepLakeLoader' object has no attribute 'split_data'"
     ]
    }
   ],
   "source": [
    "db = DeepLakeLoader('data/salestesting.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = db.query_db(detected_objection)\n",
    "# TODO INCOMPLETE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
